@Book{oai:eprints.pascal-network.org:1211,
  title =       "Gaussian Processes for Machine Learning",
  author =      "Carl Edward Rasmussen and Christopher Williams",
  publisher =   "MIT Press",
  year =        "2006",
  abstract =    "Publisher's description: Gaussian processes (GPs)
                 provide a principled, practical, probabilistic approach
                 to learning in kernel machines. GPs have received
                 increased attention in the machine-learning community
                 over the past decade, and this book provides a
                 long-needed systematic and unified treatment of
                 theoretical and practical aspects of GPs in machine
                 learning. The treatment is comprehensive and
                 self-contained, targeted at researchers and students in
                 machine learning and applied statistics. The book deals
                 with the supervised-learning problem for both
                 regression and classification, and includes detailed
                 algorithms. A wide variety of covariance (kernel)
                 functions are presented and their properties discussed.
                 Model selection is discussed both from a Bayesian and a
                 classical perspective. Many connections to other
                 well-known techniques from machine learning and
                 statistics are discussed, including support-vector
                 machines, neural networks, splines, regularization
                 networks, relevance vector machines and others.
                 Theoretical issues including learning curves and the
                 PAC-Bayesian framework are treated, and several
                 approximation methods for learning with large datasets
                 are discussed. The book contains illustrative examples
                 and exercises, and code and datasets are available on
                 the Web. Appendixes provide mathematical background and
                 a discussion of Gaussian Markov processes.",
  bibsource =   "OAI-PMH server at eprints.pascal-network.org",
  oai =         "oai:eprints.pascal-network.org:1211",
  subject =     "Learning/Statistics \& Optimisation; Theory \&
                 Algorithms",
  type =        "NonPeerReviewed",
  URL =         "http://eprints.pascal-network.org/archive/00001211/;
                 http://mitpress.mit.edu/catalog/item/default.asp?ttype=2\&tid=10930",
}

@PhdThesis{SnelsonThesis,
  title =       "Flexible and efficient Gaussian process models for
                 machine learning",
  author =      "Edward Lloyd Snelson",
  year =        "2008",
  month =       feb # "~06",
  abstract =    "2007 I, Edward Snelson, confirm that the work
                 presented in this thesis is my own. Where information
                 has been derived from other sources, I confirm that
                 this has been indi-cated in the thesis. 2 Gaussian
                 process (GP) models are widely used to perform Bayesian
                 nonlinear re-gression and classification --- tasks that
                 are central to many machine learning prob-lems. A GP is
                 nonparametric, meaning that the complexity of the model
                 grows as more data points are received. Another
                 attractive feature is the behaviour of the error bars.
                 They naturally grow in regions away from training data
                 where we have high uncertainty about the interpolating
                 function. In their standard form GPs have several
                 limitations, which can be divided into two broad
                 categories: computational difficulties for large data
                 sets, and restrictive modelling assumptions for complex
                 data sets. This thesis addresses various aspects",
  school = "Gatsby Computational Neuroscience Unit, University College London",
  bibsource =   "OAI-PMH server at citeseerx.ist.psu.edu",
  contributor =  "CiteSeerX",
  language =    "en",
  oai =         "oai:CiteSeerXPSU:10.1.1.62.4041",
  relation =    "10.1.1.28.8311",
  rights =      "Metadata may be used without restrictions as long as
                 the oai identifier remains attached to it.",
  URL =
"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.62.4041;
                 http://www.gatsby.ucl.ac.uk/~snelson/thesis.pdf",
}

@InProceedings{conf/nips/2005,
  title =       "Sparse Gaussian Processes using Pseudo-inputs",
  author =      "Edward Snelson and Zoubin Ghahramani",
  year =        "2005",
  bibdate =     "2006-02-15",
  bibsource =   "DBLP,
                 http://dblp.uni-trier.de/db/conf/nips/nips2005.html#SnelsonG05",
  booktitle =   "NIPS",
  URL =         "http://books.nips.cc/papers/files/nips18/NIPS2005_0543.pdf",
}

@InProceedings{conf/uai/SnelsonG06,
  title =       "Variable Noise and Dimensionality Reduction for Sparse
                 Gaussian processes",
  author =      "Edward Snelson and Zoubin Ghahramani",
  publisher =   "AUAI Press",
  year =        "2006",
  bibdate =     "2007-07-26",
  bibsource =   "DBLP,
                 http://dblp.uni-trier.de/db/conf/uai/uai2006.html#SnelsonG06",
  booktitle =   "UAI",
  ISBN =        "0-9749039-2-2",
  URL =
"http://uai.sis.pitt.edu/displayArticleDetails.jsp?mmnu=1&amp;smnu=2&amp;article_id=1316&amp;proceeding_id=22",
}

@InProceedings{conf/nips/SnelsonRG03,
  title =       "Warped Gaussian Processes",
  author =      "Edward Snelson and Carl Edward Rasmussen and Zoubin
                 Ghahramani",
  publisher =   "MIT Press",
  year =        "2003",
  bibdate =     "2004-10-12",
  bibsource =   "DBLP,
                 http://dblp.uni-trier.de/db/conf/nips/nips2003.html#SnelsonRG03",
  booktitle =   "NIPS",
  editor =      "Sebastian Thrun and Lawrence K. Saul and Bernhard
                 Sch{\"o}lkopf",
  ISBN =        "0-262-20152-6",
  URL =         "http://books.nips.cc/papers/files/nips16/NIPS2003_AA43.pdf",
}

@InProceedings{conf/icml/WalderKS08,
  title =       "Sparse multiscale gaussian process regression",
  author =      "Christian Walder and Kwang In Kim and Bernhard
                 Sch{\"o}lkopf",
  bibdate =     "2008-08-14",
  bibsource =   "DBLP,
                 http://dblp.uni-trier.de/db/conf/icml/icml2008.html#WalderKS08",
  booktitle =   "Machine Learning, Proceedings of the Twenty-Fifth
                 International Conference ({ICML} 2008), Helsinki,
                 Finland, June 5-9, 2008",
  publisher =   "ACM",
  year =        "2008",
  volume =      "307",
  editor =      "William W. Cohen and Andrew McCallum and Sam T.
                 Roweis",
  ISBN =        "978-1-60558-205-4",
  pages =       "1112--1119",
  series =      "ACM International Conference Proceeding Series",
  URL =         "http://doi.acm.org/10.1145/1390156.1390296",
}

@Journal{Foster2009,
  author =      "Leslie Foster and Alex Waagen and Nabeela Aijaz and
                 Michael Hurley and Apolonio Luis and Joel Rinsky and
                 Chandrika Satyavolu and Michael J. Way and Paul Gazis
                 and Ashok Srivastava",
  title =       "Stable and Efficient Gaussian Process Calculations",
  journal =     "Journal of Machine Learning Research",
  publisher =   "Microtome Publishing",
  volume =      "10",
  pages =       "857--882",
  ISSN =        "1533-7928 (electronic); 1532-4435 (paper)",
  year =        "2009",
  month =       apr,
  abstract =    "The use of Gaussian processes can be an effective
                 approach to prediction in a supervised learning
                 environment. For large data sets, the standard Gaussian
                 process approach requires solving very large systems of
                 linear equations and approximations are required for
                 the calculations to be practical. We will focus on the
                 subset of regressors approximation technique. We will
                 demonstrate that there can be numerical instabilities
                 in a well known implementation of the technique. We
                 discuss alternate implementations that have better
                 numerical stability properties and can lead to better
                 predictions. Our results will be illustrated by looking
                 at an application involving prediction of galaxy
                 redshift from broadband spectrum data.",
  URL =         "http://www.jmlr.org/jmlr.xml;
                 http://www.jmlr.org/style.css;
                 http://www.jmlr.org/papers/volume10/foster09a/foster09a.pdf;
                 http://www.jmlr.org; http://www.jmlr.org/; /papers;
                 /author-info.html; /news.html; /scope.html;
                 /editorial-board.html; /announcements.html;
                 /proceedings; /mloss; /search-jmlr.html; /manudb;
                 /jmlr.xml",
}

@techreport{Titsias2009,
  author = "Michalis K.\ Titsias",
  title = "Variational Model Selection for Sparse Gaussian Process Regression",
  institution = "School of Computer Science, University of Manchester, UK",
  year = "2009",
  URL = "http://www.cs.manchester.ac.uk/~mtitsias/papers/sparseGPv2.pdf",
}

@inproceedings{DBLP:conf/nips/AlvarezL08,
  author    = {Mauricio Alvarez and
               Neil D. Lawrence},
  title     = {Sparse Convolved Gaussian Processes for Multi-output Regression},
  booktitle = {NIPS},
  year      = {2008},
  pages     = {57-64},
  ee        = {http://books.nips.cc/papers/files/nips21/NIPS2008_0170.pdf},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@book{MatrixAnalysis,
  editor = {Meyer, Carl D.},
  title = {Matrix analysis and applied linear algebra},
  year = {2000},
  isbn = {0-89871-454-0},
  publisher = {Society for Industrial and Applied Mathematics},
  address = {Philadelphia, PA, USA},
}

@book{BishopMachLearn,
  abstract = {{The dramatic growth in practical applications for machine
  learning over the last ten years has been accompanied by many important
  developments in the underlying algorithms and techniques. For example,
  Bayesian methods have grown from a specialist niche to become mainstream,
  while graphical models have emerged as a general framework for describing and
  applying probabilistic techniques. The practical applicability of Bayesian
  methods has been greatly enhanced by the development of a range of approximate
  inference algorithms such as variational Bayes and expectation propagation,
  while new models based on kernels have had a significant impact on both
  algorithms and applications. This completely new textbook reflects these
  recent developments while providing a comprehensive introduction to the fields
  of pattern recognition and machine learning. It is aimed at advanced
  undergraduates or first-year PhD students, as well as researchers and
  practitioners. No previous knowledge of pattern recognition or machine
  learning concepts is assumed.  Familiarity with multivariate calculus and
  basic linear algebra is required, and some experience in the use of
  probabilities would be helpful though not essential as the book includes a
  self-contained introduction to basic probability theory. The book is suitable
  for courses on machine learning, statistics, computer science, signal
  processing, computer vision, data mining, and bioinformatics. Extensive
  support is provided for course instructors, including more than 400 exercises,
  graded according to difficulty. Example solutions for a subset of the
  exercises are available from the book web site, while solutions for the
  remainder can be obtained by instructors from the publisher. The book is
  supported by a great deal of additional material, and the reader is encouraged
  to visit the book web site for the latest information. A forthcoming companion
  volume will deal with practical aspects of pattern recognition and machine
  learning, and will include free software implementations of the key algorithms
  along with example data sets and demonstration programs.  Christopher Bishop
  is Assistant Director at Microsoft Research Cambridge, and also holds a Chair
  in Computer Science at the University of Edinburgh. He is a Fellow of Darwin
  College Cambridge, and was recently elected Fellow of the Royal Academy of
  Engineering. The author's previous textbook "Neural Networks for Pattern
  Recognition" has been widely adopted.}},
  author = {Bishop, Christopher M.},
  citeulike-article-id = {873540},
  citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0387310738},
  citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0387310738},
  citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0387310738},
  citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0387310738},
  citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0387310738/citeulike00-21},
  citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0387310738},
  citeulike-linkout-6 = {http://www.worldcat.org/isbn/0387310738},
  citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0387310738},
  citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0387310738&index=books&linkCode=qs},
  citeulike-linkout-9 = {http://www.librarything.com/isbn/0387310738},
  day = {01},
  edition = {1},
  howpublished = {Hardcover},
  isbn = {0387310738},
  keywords = {book, machine\_learning, pattern\_classification},
  month = {October},
  posted-at = {2007-10-28 16:57:29},
  priority = {0},
  publisher = {Springer},
  title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
  url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0387310738},
  year = {2007}
}
